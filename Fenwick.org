#+title: Fenwick Tree in Haskell
#+author: Parsa Alizadeh

* Generic Fenwick Tree

Fenwick tree are known to be really fast. The important tricks are using arrays and indices directly
to locate nodes in the tree. To implement this I need to use ~IO~ or ~ST~ monad, using either
~Array~, ~Vector~, or ~PrimArray~.

** Issues with generic data types

I want the user be able to create a ~newtype~ over ~Int~ for example, and define their own ~Monoid~
or ~Semigroup~ instance for it. The fact that the underlying type is ~Int~ means the operations can
be done in an unboxed array. The problem is that unboxed array do not work with new types very
easily.

One workaround was to use GeneralizedNewTypeDeriving, but after researching, it seems that GND only
works when the type role is nominal, and in unboxed array implementations they are not nominal. (See
[[https://gitlab.haskell.org/ghc/ghc/-/issues/9220][ghc issue #9220]]).

** Prototype using boxed arrays

I've done implementing ~FenIOArray~. It passes manual tests but needs stress testing and
benchmarking. I want to see the bottlenecks too.

Function names are not great and need to be changed.

Semantic of specifying a range is not defined well. We can go with [l, r) or [1, r) in the case of
prefixes or the full range [l, r] and [1, r].

Haskell indices help for 1-based trees in fenwick implementation. I want to see if they have any
runtime overhead.

Monoids in fenwick should be cumtative. This means ~[]~ or ~First~ are not applicable to fenwicks.

Need to think about monoids of sum modulo m, or products modulo p. They are mathematically groups,
but not straightforward monoids and groups in Haskell. I want to make sure when the modulo is
constant the compiler should optimize it.

See [[https://en.wikipedia.org/wiki/Fenwick_tree][Wikipedia Fenwick tree]]. Also there maybe functions for least significant bit in ~Data.Bits~.

** Coercible Array
<2025-03-14 Fri>

I come with an idea that I haven't seen anywhere. The idea is to represent coercible arrays in a
newtype.

#+begin_src haskell
  newtype ArrayC array rep ix elem = ArrayC (array ix rep)

  instance (IArray array rep, Coercible rep elem) => IArray (ArrayC array rep) elem where { ... }

  instance (Monad m, MArray array rep m, Coercible rep elem) => MArray (ArrayC array rep) elem m where { ... }
#+end_src

Why do I like this idea?
1. I thought implementing ~IArray~ and ~MArray~ would be impossible, but I can compile the above
   code. I think the main reason is using a newtype rather that trying to implement unboxed versions
   directly for newtypes. I own the newtype, so I can implement the instances!
2. There is nothing about boxed or unboxed in the code. This is supports any kind of newtypes for
   any kind of arrays. Although arrays are limited to ~ST~ and ~IO~ arrays mostly, but the idea can
   be applied if it was needed.
3. I didn't benchmark it yet, but I think the overhead of coerce is zero. So the unboxed arrays of
   newtypes have the same speed as the underlying arrays.
4. It is much simpler than ~Data.Vector~.

Why didn't I see this idea sooner?
1. One limiting reason of this idea is using tuples. Tuples are necessary for data structures too.
   Although I haven't seen any Fenwicks with complex data types, it might happend theoritcally, and
   ~Data.Vector~ somehow supports it while unboxed ~IO~ and ~ST~ have no support for pairs or
   tuples.
2. Maybe I was ignorant. See [[https://hackage.haskell.org/package/vector-0.13.2.0/docs/Data-Vector-Unboxed.html#t:As][Data.Vector As]] newtype.

I implement instances manually, although I would assume there is an easier way with DerivingVia or
other similar extenstions. Also I could use coerce, but they need lots of type application.

It is possible to implement arrays for Enums too (for example a sum type in Haskell can be written
as an unboxed array).

** Modulo type
<2025-03-15 Sat>

I found [[https://stackoverflow.com/questions/39674555/haskell-how-to-write-a-monoid-instance-for-something-that-depends-on-paramete][a question]] on stackoverflow that helped to implement ~Modulo~ type. The mod is in the type
and the compiler should be able to optimize it. Another good thing is that ~GHC.TypeLits~ keeps the
number as a ~Word~ instead of ~S (S (...))~ which is ideal in this case.

I also implemented ~SumMod~ and ~ProductMod~ seperately but realized that ~Sum~ and ~Product~ are
enough! The only exception is ~Group~ instance for ~Product (Modulo a m)~ which assumes ~m~ is
prime.

Another assumption that I didn't think about how to represent is the fact that monoids and groups
defined for Fenwick must be abelian and commutative. I can restrict using general Monoids by
implementing a dummy instance ~AbelianMonoid~ and implement valid instances.

** Profiling
<2025-03-16 Sun>

I tried to compare a C++ implementation with my own. Both of the files are self-contained (in theory
they can be compiled statically, but currently the only way I can compile Haskell is with
~-dynamic~). Both of them are compiled with ~-O2~. The core implmentation of Fenwick is completely
the same with C++ and Haskell (Haskell allows more abstraction by the way). For a brief moment I
thought Haskell version is faster, but I was wrong.

C++ version takes a long time on IO, but with scanf/printf or ~sync_with_stdio(false)~ it is more
than 2x faster than Haskell version. If I don't apply any IO optimization to C++, it takes about 20%
more than Haskell version.

This is actually interesting. The only IO optimization in Haskell is with ~readInts~ function. This
is only parsing number using ~ByteString~ library, and there are no explicit optimization to
buffering or similer topics.

Also, profiling helped me to test the code too. It passes the the testcases and outputs the same as
the C++ version.

I used ~perf~ to see the bottlenecks. In C++ bottleneck is correctly within the Fenwick code, while
in Haskell about 15% of runtime is in the base library. This might indicate there are more IO
optmization in Haskell than I know about.

*** ByteString

I did notice in ~perf~ that a chunk of time is related to ~show~ function. It did actually make
sense! I changed every ~print~ to a ByteString version ~printInt~:

#+begin_src haskell
printInts :: [Int] -> IO ()
printInts xs = hPutBuilder stdout (go <> char7 '\n') where
  go = mconcat . intersperse (char7 ' ') . map intDec $ xs

printInt :: Int -> IO ()
printInt x = hPutBuilder stdout (intDec x <> char7 '\n')
#+end_src

The ratio between C++ and Haskell is very close to 2x. I see with ~perf~ that the main bottleneck is
at Fenwick, but some of it is related to ~modifyArray~ which worries me. There are also bound
checking in haskell that might improve the runtime.

*** unsafeRead and unsafeWrite

They have very minimal effect on the runtime, probably less than 10%.
